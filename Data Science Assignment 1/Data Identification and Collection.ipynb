{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3aa53cc",
   "metadata": {},
   "source": [
    "# COMP47670 - Assignment 1 by Peter Coogan (21202781)\n",
    "\n",
    "## Data Identification and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1df1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d93b79",
   "metadata": {},
   "source": [
    "### Chosen API\n",
    "The chosen API is the USGS Earthquake Catalog - https://earthquake.usgs.gov/fdsnws/event/1\n",
    "\n",
    "### Functions to Collect Data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c660f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_write_headings(file_name, headings): \n",
    "    with open(file_name, \"w\") as write_file:\n",
    "        f = csv.writer(write_file)\n",
    "        f.writerow(headings)\n",
    "    \n",
    "    return\n",
    "\n",
    "def get_headings(raw_html):\n",
    "    headings_long_string = raw_html.split('\\n', 1)[0] # get the headings\n",
    "    headings = headings_long_string.split(',') # split the headings string\n",
    "    # insert a date heading and below, the date and time string is separated\n",
    "    headings.insert(0, 'date')\n",
    "    return headings\n",
    "\n",
    "def get_lines(raw_html):\n",
    "    # get the raw data as a list of lines \n",
    "    lines_long_string = raw_html.split('\\n', 1)[1]\n",
    "    lines = lines_long_string.split('\\n')\n",
    "    return lines\n",
    "\n",
    "def write_data_to_file(file_name, url):\n",
    "    response = urllib.request.urlopen(url) # request\n",
    "    raw_html = response.read().decode() # decode request\n",
    "    # get the headings from the html\n",
    "    headings = get_headings(raw_html)\n",
    "    # create the CSV file to store the data and add the headings\n",
    "    create_and_write_headings(file_name, headings)\n",
    "    # get the rest of the lines from the html\n",
    "    lines = get_lines(raw_html)\n",
    "    \n",
    "    with open(file_name, 'a') as write_file:\n",
    "        f = csv.writer(write_file)\n",
    "        for line in lines:\n",
    "            \n",
    "            # blank lines can appear so ignore them\n",
    "            if line == '':\n",
    "                continue\n",
    "            # remove the 'place' string in double quotes that causes issues\n",
    "            remove = (line.split('\"'))[1].split('\"')[0]\n",
    "            line = line.replace(remove, '')\n",
    "            \n",
    "            # separate the date and time string\n",
    "            date_and_time = line.split('Z')[0] + 'Z'\n",
    "            date = line.split('T')[0]\n",
    "            time = (line.split('T'))[1].split('Z')[0]\n",
    "            line = line.replace(date_and_time, date + ',' + time)\n",
    "            \n",
    "            # finally split the line at the commas and write it to file\n",
    "            line = line.split(',')\n",
    "            f.writerow(line)\n",
    "    return\n",
    "    \n",
    "    \n",
    "# generate the desired request and write the data\n",
    "def raw_data_parser(file_name, starttime=\"\", endtime=\"\", minlatitude=\"-90\", minlongitude=\"-180\", maxlatitude=\"90\",\n",
    "                    maxlongitude=\"180\", limit=\"20000\", maxdepth=\"1000\", mindepth=\"-100\", maxmagnitude=\"\", minmagnitude=\"\",\n",
    "                    orderby=\"time\"):\n",
    "    # ideally this string would be split over multiple lines however I have been unable to successfully implement this\n",
    "    url = \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=csv\" + \"&starttime=\" + starttime + \"&endtime=\" + endtime + \"&minlatitude=\" + minlatitude + \"&minlongitude=\" + minlongitude + \"&maxlatitude=\" + maxlatitude + \"&maxlongitude=\" + maxlongitude + \"&limit=\" + limit + \"&maxdepth=\" + maxdepth + \"&mindepth=\" + mindepth + \"&maxmagnitude=\" + maxmagnitude + \"&minmagnitude=\" + minmagnitude + \"&orderby=\" + orderby\n",
    "    \n",
    "    write_data_to_file(file_name, url)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5dc3b",
   "metadata": {},
   "source": [
    "### Fetch data for the past 20 years for earthquakes over magnitude 6\n",
    "- These events are located within the 'Pacific Ring of Fire' which is a region of high tectonic activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b8075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default starttime is now - 30 days\n",
    "# default endtime is now\n",
    "twenty_year_highMag_data = \"highMag_data_file.csv\"\n",
    "starttime = \"2001-01-01\"\n",
    "endtime = \"2021-01-01\"\n",
    "minlatitude = \"-55\"\n",
    "maxlatitude = \"65\"\n",
    "minlongitude = \"120\"\n",
    "maxlongitude = \"290\"\n",
    "minmagnitude = \"6\"\n",
    "raw_data_parser(twenty_year_highMag_data, starttime=starttime, endtime=endtime, minlatitude=minlatitude, minlongitude=minlongitude,\n",
    "               maxlatitude=maxlatitude, maxlongitude=maxlongitude, minmagnitude=minmagnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf51879",
   "metadata": {},
   "source": [
    "### Fetch data for the last 50 years for earthquakes over magnitude 6\n",
    "- These events are located within the 'Pacific Ring of Fire' which is a region of high tectonic activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad3086b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fifty_year_highMag_data = \"long_time_data_file.csv\"\n",
    "starttime = \"1971-01-01\"\n",
    "endtime = \"2021-01-01\"\n",
    "minlatitude = \"-55\"\n",
    "maxlatitude = \"65\"\n",
    "minlongitude = \"120\"\n",
    "maxlongitude = \"290\"\n",
    "minmagnitude = \"6\"\n",
    "raw_data_parser(fifty_year_highMag_data, starttime=starttime, endtime=endtime, minlatitude=minlatitude, minlongitude=minlongitude,\n",
    "               maxlatitude=maxlatitude, maxlongitude=maxlongitude, minmagnitude=minmagnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f2c77",
   "metadata": {},
   "source": [
    "### Fetch data for the last 50 years for earthquakes in Ireland\n",
    "- Earthquake data for Ireland only goes back to 1981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69b69be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ireland_data = \"Ireland_data_file.csv\"\n",
    "starttime = \"1971-01-01\"\n",
    "minlatitude = \"51\"\n",
    "maxlatitude = \"55\"\n",
    "minlongitude = \"-11\"\n",
    "maxlongitude = \"-5\"\n",
    "raw_data_parser(Ireland_data, starttime=starttime, minlatitude=minlatitude, minlongitude=minlongitude,\n",
    "               maxlatitude=maxlatitude, maxlongitude=maxlongitude)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
